{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KUCUBE Image Compression",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPiCy4rXRLuj/hRO1t0Vjmn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/SCALSTEIN/b9adc643ba79b24e96b67bf6d5daf9c1/kucube-image-compression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrCrVmmPwDeh"
      },
      "source": [
        "Compress arbitrary images in Colab using a pretrained neural compression model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dsz342EEwE2w"
      },
      "source": [
        " This is a Pytorch port of the High-Fidelity Image Compression project\n",
        " https://hific.github.io/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgKifKOfwsPo"
      },
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCvoWxq6wvfv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M227Y3aWcott"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import urllib\n",
        "import zipfile\n",
        "import collections\n",
        "\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "from IPython.display import Image as DisplayImage\n",
        "from IPython.display import Javascript\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "INPUT_DIR = '/content/files'\n",
        "STAGING_DIR = '/content/stage'\n",
        "OUT_DIR = '/content/out'\n",
        "CKPT_DIR = '/content/checkpoint'\n",
        "DEFAULT_IMAGE_PREFIX = ('https://storage.googleapis.com/hific/clic2020/images/originals/')\n",
        "\n",
        "File = collections.namedtuple('File', ['output_path', 'compressed_path',\n",
        "                                       'num_bytes', 'bpp'])\n",
        "\n",
        "_ = [os.makedirs(dir, exist_ok=True) for dir in (INPUT_DIR, STAGING_DIR, OUT_DIR,\n",
        "                                                 CKPT_DIR)]\n",
        "original_sizes = dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPU2WMlMZviB"
      },
      "source": [
        "def get_default_image(output_dir, image_choice=\"portrait\"):\n",
        "    image_ID = dict(cafe=\"b1b8f33917a40c9d0b118ef801de67d4.png\",\n",
        "                    cat=\"4fa92b8ecb4ee46a942837447de1ac5c.png\",\n",
        "                    city=\"b98ec5b29d02ef65e57d23ef90660b4d.png\",\n",
        "                    clocktower=\"9cbf2594f339c0d3d0f0ea25c62af52b.png\",\n",
        "                    fresco=\"8181526d9f238726d3e1d3ec3cc56fb7.png\",\n",
        "                    islet=\"c6658d87c608b631f5cc3fb5a8d89731.png\",\n",
        "                    mountain=\"d3688a7285d7b2b81febe1cd72e6e22c.png\",\n",
        "                    pasta=\"f5be5054c01d8efc834d78a991356ad6.png\",\n",
        "                    pines=\"e903c4f4684100a6dbac1f0b9b4de760.png\",\n",
        "                    plaza=\"d78b363974ac79908b79012f48de715d.png\",\n",
        "                    portrait=\"ad249bba099568403dc6b97bc37f8d74.png\",\n",
        "                    shoreline=\"b9bad0c68eb9ce94e02e9698c8cc429a.png\",\n",
        "                    street=\"90b622e11ecc37edd42297427403ee81.png\",\n",
        "                    tundra=\"cc831c904a314a0e98530124526e930b.png\",\n",
        "                    )[image_choice]\n",
        "\n",
        "    default_image_url = os.path.join(DEFAULT_IMAGE_PREFIX, image_ID)\n",
        "    output_path = os.path.join(output_dir, os.path.basename(default_image_url))\n",
        "    print('Downloading', default_image_url, '\\n->', output_path)\n",
        "    urllib.request.urlretrieve(default_image_url, output_path)\n",
        "\n",
        "def get_model_checkpoint(output_dir, model_ID, model_choice, alternative=False,\n",
        "                         overwrite=False):\n",
        "    output_path = os.path.join(output_dir, f'{model_choice.lower()}.pt')\n",
        "    if overwrite is True:\n",
        "        print('Overwriting file, if it exists.')\n",
        "        !rm -v $output_path\n",
        "    else:\n",
        "        if os.path.exists(output_path):\n",
        "            print('File already exists at', '\\n->', output_path)\n",
        "            return output_path\n",
        "    print('Downloading model to', '\\n->', output_path)\n",
        "    if alternative is True:\n",
        "        !wget \"https://zenodo.org/record/4026003/files/$model_ID\" -O $output_path\n",
        "    else:\n",
        "        !wget -q --show-progress --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=$model_ID' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=$model_ID\" -O $output_path && rm -rf /tmp/cookies.txt\n",
        "\n",
        "    return output_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-5CdgZHxFzP"
      },
      "source": [
        "Higher bitrates result in higher-fidelity reconstructions, at the expense of increased message length. HIFIC-low is the model with the highest compression ratio (lowest output filesize), and HIFIC-high is the model with the lowest compression ratio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_CEzeTlxIGv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulxLn5j7n_an"
      },
      "source": [
        "# Enter choice to right\n",
        "model_choice = 'HIFIC-med' #@param [\"HIFIC-low\", \"HIFIC-med\", \"HIFIC-high\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJJGfQ3mxTgH"
      },
      "source": [
        "Clone repo and grab the model checkpoint (around 2 GB)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FODQo8ERxVNn"
      },
      "source": [
        "# Drive IDs\n",
        "model_choices = {'HIFIC-low': '1hfFTkZbs_VOBmXQ-M4bYEPejrD76lAY9',\n",
        "                 'HIFIC-med': '1QNoX0AGKTBkthMJGPfQI0dT0_tnysYUb',\n",
        "                 'HIFIC-high': '1BFYpvhVIA_Ek2QsHBbKnaBE8wn1GhFyA'}\n",
        "\n",
        "model_ID = model_choices[model_choice]\n",
        "model_path = get_model_checkpoint(CKPT_DIR, model_ID, model_choice)\n",
        "first_model_init = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBVs1_4dxbOH"
      },
      "source": [
        "# Don't run this if the download from Drive was successful!\n",
        "model_choices = {'HIFIC-low': 'hific_low.pt?download=1',\n",
        "                 'HIFIC-med': 'hific_med.pt?download=1',\n",
        "                 'HIFIC-high': 'hific_hi.pt?download=1'}\n",
        "\n",
        "model_ID = model_choices[model_choice]\n",
        "model_path = get_model_checkpoint(CKPT_DIR, model_ID, model_choice, \n",
        "                                  alternative=True, overwrite=True)\n",
        "first_model_init = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0SCsJGxx9P_"
      },
      "source": [
        " you can use the Files tab on the left and select the Upload to session storage icon to upload more custom images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_R1tmsqyLSv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJZlFxcNyK2M"
      },
      "source": [
        "custom_image = True #@param [\"False\", \"True\"] {type:\"raw\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQNR8HgnyR7w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37LNwIexHmu8"
      },
      "source": [
        "# Choose default images from CLIC2020 dataset\n",
        "# Skip if uploading custom images\n",
        "default_image = \"portrait\" #@param [\"cafe\", \"cat\", \"city\", \"clocktower\", \"fresco\", \"islet\", \"mountain\", \"pasta\", \"pines\", \"plaza\", \"portrait\", \"shoreline\", \"street\", \"tundra\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_S4bo4vhU_P"
      },
      "source": [
        "if custom_image is True:\n",
        "    print('Using user-defined images.')\n",
        "    # Get dict of upload files\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for fn in uploaded.keys():\n",
        "        print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "            name=fn, length=len(uploaded[fn])))\n",
        "        !mv -iv $fn $INPUT_DIR\n",
        "else:\n",
        "    print('Using default image.')\n",
        "    # Download default image\n",
        "    get_default_image(INPUT_DIR, default_image)\n",
        "\n",
        "all_files = os.listdir(INPUT_DIR)\n",
        "print(f'Got following files ({len(all_files)}):')\n",
        "scale_factor = 2 if len(all_files) == 1 else 4\n",
        "\n",
        "for file_name in all_files:\n",
        "    img = Image.open(os.path.join(INPUT_DIR, file_name))\n",
        "    w, h = img.size\n",
        "    img = img.resize((w // scale_factor, h // scale_factor))\n",
        "    print('-> ' + file_name + ':')\n",
        "    display(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd02HOhLBj6e"
      },
      "source": [
        "SUPPORTED_EXT = {'.png', '.jpg'}\n",
        "\n",
        "all_files = os.listdir(INPUT_DIR)\n",
        "if not all_files:\n",
        "    raise ValueError(\"Please upload/download images!\")\n",
        "\n",
        "def get_bpp(image_dimensions, num_bytes):\n",
        "    w, h = image_dimensions\n",
        "    return num_bytes * 8 / (w * h)\n",
        "\n",
        "def has_alpha(img_p):\n",
        "    im = Image.open(img_p)\n",
        "    return im.mode == 'RGBA'\n",
        "\n",
        "!rm -v $STAGING_DIR/*\n",
        "\n",
        "for file_name in all_files:\n",
        "    if os.path.isdir(file_name):\n",
        "        continue\n",
        "    if not any(file_name.endswith(ext) for ext in SUPPORTED_EXT):\n",
        "        print('Skipping non-image', file_name, '...')\n",
        "        continue\n",
        "    full_path = os.path.join(INPUT_DIR, file_name)\n",
        "    if has_alpha(full_path) is True:\n",
        "        print('Skipping because of alpha channel:', file_name)\n",
        "        continue\n",
        "    \n",
        "    file_name, _ = os.path.splitext(file_name)\n",
        "    original_sizes[file_name] = os.path.getsize(full_path)\n",
        "    output_path = os.path.join(OUT_DIR, f'{file_name}.png')\n",
        "    !mv -v $full_path $STAGING_DIR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gWD2iHMyqku"
      },
      "source": [
        "Enabling GPU\n",
        "GPU should be enabled for this Colab. If the next cell prints a warning, do the following:\n",
        "\n",
        "Navigate to Edit â†’> Notebook Settings\n",
        "Select GPU from the Hardware Accelerator drop-down"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM20v7ptyzvW"
      },
      "source": [
        "if torch.cuda.is_available() is False:\n",
        "  print('WARNING: No GPU found. Compression/decompression will be slow!')\n",
        "else:\n",
        "  print(f'Found GPU {torch.cuda.get_device_name(0)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VW9UQBoYy_xO"
      },
      "source": [
        "Compress Images\n",
        "You only need to run the following cell once per session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeIsfPxcG1Ro"
      },
      "source": [
        "# Setup model\n",
        "if first_model_init is False:\n",
        "    print('Building model ...')\n",
        "    model, args = prepare_model(model_path, STAGING_DIR)\n",
        "    first_model_init = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbiUOrJbzUbu"
      },
      "source": [
        "Encode images and save compressed format to disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHgSCmS5RRZ1"
      },
      "source": [
        "%%time\n",
        "data_loader = prepare_dataloader(args, STAGING_DIR, OUT_DIR)\n",
        "compress_and_save(model, args, data_loader, OUT_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FARMLHaa1Crt"
      },
      "source": [
        "# Check compressed filesizes\n",
        "!ls -ltrh $OUT_DIR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LF4Var_tzfJ-"
      },
      "source": [
        "Load compressed format from disk and decode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ2vMMkVzgYG"
      },
      "source": [
        "all_outputs = []\n",
        "\n",
        "for compressed_file in glob.glob(os.path.join(OUT_DIR, '*.hfc')):\n",
        "    file_name, _ = os.path.splitext(compressed_file)\n",
        "    output_path = os.path.join(OUT_DIR, f'{file_name}.png')\n",
        "\n",
        "    # Model decode\n",
        "    reconstruction = load_and_decompress(model, compressed_file, output_path)\n",
        "    \n",
        "    all_outputs.append(File(output_path=output_path,\n",
        "                            compressed_path=compressed_file,\n",
        "                            num_bytes=os.path.getsize(compressed_file),\n",
        "                            bpp=get_bpp(Image.open(output_path).size, os.path.getsize(compressed_file))))\n",
        "                            \n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mDC_7r8zo6W"
      },
      "source": [
        " Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nVCPeDnskD8"
      },
      "source": [
        "def print_html(html):\n",
        "    display(HTML(html + '<br/>'))\n",
        "\n",
        "def make_cell_large():\n",
        "    display(Javascript(\n",
        "        '''google.colab.output.setIframeHeight(0, true, {maxHeight: 5192})'''))\n",
        "\n",
        "make_cell_large()  # Larger output window.\n",
        "\n",
        "for file in all_outputs:\n",
        "    print_html('<hr/>')\n",
        "    file_name, _ = os.path.splitext(file.output_path)\n",
        "    original_size = original_sizes[os.path.basename(file_name).split('_compressed')[0]]\n",
        "    print(f'Showing {file.output_path} | {file.num_bytes//1000} kB (compressed) | {file.bpp:.4f} bpp | Original: {original_size//1000} kB')\n",
        "    display(Image.open(file.output_path))\n",
        "    print_html('<hr/>')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss1PgQQLz4zu"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b-wkBnyrTAR"
      },
      "source": [
        "### Download compressed images\n",
        "\n",
        "Files are saved as PNG for viewing.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn3epZhUYWOw"
      },
      "source": [
        "download_outputs = True #@param [\"False\", \"True\"] {type:\"raw\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BKccvcTpj1k"
      },
      "source": [
        "if download_outputs is True:\n",
        "    ZIP = '/content/hific_compressed_images.zip'\n",
        "\n",
        "    with zipfile.ZipFile(ZIP, 'w') as zf:\n",
        "        for f in all_outputs:\n",
        "            path_with_bpp = f.output_path.replace('.png', f'-{f.bpp:.3f}bpp.png')\n",
        "            zf.write(f.output_path, os.path.basename(path_with_bpp))\n",
        "\n",
        "    files.download(ZIP) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}